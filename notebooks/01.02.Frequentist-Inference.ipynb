{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Algorithms and Inference](01.01.Algorithms-and-Inference.ipynb) | [Conteúdo](Index.ipynb) | [Bayesian Inference] >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fmafonseca/casi/blob/master/notebooks/01.02.Frequentist-Inference.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Frequentist Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glomerular Filtration data of Table 2.1 and elsewhere\n",
    "\n",
    "Os dados utilizados aqui são os disponibilizados no próprio site do livro através da URL https://web.stanford.edu/~hastie/CASI/data.html.\n",
    "\n",
    "Dados:\n",
    "- *Measurements of glomerular filtration rate for 211 kidney patients from the Nephrology laboratory of Dr Bryan Myers at Stanford University.*\n",
    "- https://web.stanford.edu/~hastie/CASI_files/DATA/gfr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   glr\n",
       "0  108\n",
       "1   91\n",
       "2   62\n",
       "3   59\n",
       "4   84"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gfr_df = pd.read_csv(\"data/gfr.txt\", delimiter=' ', header=None)\n",
    "gfr_df.columns = ['glr'] # rename column to 'glr'\n",
    "gfr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta seção se refere ao exemplo abaixo do livro:\n",
    "\n",
    "<blockquote>\n",
    "<em>We begin with another example from Dr. Myers’ nephrology laboratory: $211$ kidney patients have had their glomerular filtration rates measured, with the results shown in Figure 2.1; <strong><font color=green>gfr</font></strong> is an important indicator of kidney function, with low values suggesting trouble. (It is a key component of <strong><font color=green>tot</font></strong> in Figure 1.1). The mean and standard error (1.1)–(1.2) are $\\bar{x}=54.25$ and $\\hat{se}=0.95$, typically reported as</em>\n",
    "\n",
    "<p>\n",
    " $$\n",
    "54.25 \\pm 0.95\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$\\pm 0.95$ <em>denotes a <mark>frequentist inference</mark> for the accuracy of the estimate $\\bar{x}=54.25$, and <mark>suggests that we shouldn’t take the “$.25$” very seriously, even the “$4$” being open to doubt.</mark></em>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Figure 2.1 Glomerular filtration rates for 211 kidney patients\n",
    "figure_2_1 = gfr_df.hist(column='glr', bins=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of glr measurements = 211\n",
      "Mean of glr measurements = 54.27\n",
      "Estimated standard error for mean of glr measurements = 0.94\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = len(gfr_df.index)\n",
    "mean_glr = gfr_df.glr.mean()\n",
    "estimated_se_mean_glr = gfr_df.glr.std() / np.sqrt(n)\n",
    "\n",
    "print(\"Number of glr measurements = {0}\".format(n))\n",
    "print(\"Mean of glr measurements = {0:.2f}\".format(mean_glr))\n",
    "print(\"Estimated standard error for mean of glr measurements = {0:.2f}\".format(estimated_se_mean_glr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que os números calculados aqui a partir do *[data set](https://web.stanford.edu/~hastie/CASI_files/DATA/gfr.txt)* disponibilizado no site do livro estão ligeiramente diferentes do livro, ou seja, $\\bar{x}=54.27$ ao invés de $\\bar{x}=54.25$ e $\\hat{se}=0.94$ ao invés de $\\hat{se}=0.95$. Porém, isto não invalida o exemplo.\n",
    "\n",
    "Mas de onde vem esta **inferência frequentista** $\\hat{se}$ a respeito da acurácia da estimativa $\\bar{x}$?\n",
    "\n",
    "<blockquote>\n",
    "<mark>Statistical inference usually begins with the assumption that some probability model has produced the observed data</mark> $x$, in our case the vector of $n=211$ <strong><font color=green>gfr</font></strong> measurements $x = \\left( x_1, x_2, \\ldots, x_n \\right)$. Let $X = \\left( X_1, X_2, \\ldots, X_n \\right)$ indicate $n$ independent draws from a probability distribution $F$, written\n",
    "\n",
    "<p>\n",
    "$$\n",
    "F \\rightarrow X\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$F$ being the underlying distribution of possible <strong><font color=green>gfr</font></strong> scores here. A realization $X=x$ of $F \\rightarrow X$ has been observed, and the statistician wishes to <mark><em>infer</em></mark> some property of the unknown distribution $F$.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Suppose the desired property is the <em>expectation</em> of a single random draw $X$ from $F$, denoted\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\theta = E_F \\{ X \\}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "The obvious estimate of $\\theta$ is $\\hat{\\theta}=\\bar{x}$, the sample average. If $n$ were enormous, say $10^{10}$, we would expect $\\hat{\\theta}$ to nearly equal $\\theta$, but otherwise there is room for error. <mark>How much error is the inferential question</mark>.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "The estimate $\\hat{\\theta}$ is calculated from $x$ according to some known algorithm, say\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\hat{\\theta} = t \\left( x \\right) \\text{,}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$t \\left( x \\right)$ in our example being the averaging function $\\bar{x} = \\sum_{i=1}^n \\frac{x_i}{n}$; $\\hat{\\theta}$ is a realization of\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\hat{\\Theta} = t \\left( X \\right) \\text{,}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "the output of $t \\left( . \\right)$ applied to a theoretical sample $X$ from $F$. We have chosen $t \\left( X \\right)$, we hope, to make‚ $\\hat{\\Theta}$ a good estimator of $\\theta$, the desired property of $F$.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "We can now give a <font color=magenta>first definition of frequentist inference</font>: <mark><em>the accuracy of an observed estimate $\\hat{\\theta} = t \\left( x \\right)$ is the probabilistic accuracy of $\\hat{\\Theta} = t \\left( X \\right)$ as an estimator of $\\theta$</em></mark>. This may seem more a tautology than a definition, but it contains a powerful idea: <mark>$\\hat{\\theta}$ is just a single number but $\\hat{\\Theta}$ takes on a range of values whose spread can define measures of accuracy</mark>.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>\n",
    "\n",
    "Então, no exemplo do livro temos até o momento que:\n",
    "- $F$ é a distribuição de possíveis valores de **<font color=green>gfr</font>**, ou seja, é o modelo probabilístico que gerou as $n=211$ observações $x = \\left( x_1, x_2, \\ldots, x_n \\right)$ de valores de **<font color=green>gfr</font>**.\n",
    "- Estamos interessados em descobrir o valor esperado (*expectation*) de um único sorteio aleatório $X$ a partir de $F$, ou seja, queremos saber qual o valor de $\\theta = E_F \\{ X \\}$. Mas não temos $F$.\n",
    "- Uma estimativa para $\\theta$ é $\\hat{\\theta}$, ou seja, $\\theta \\approx \\hat{\\theta} = t \\left( x \\right) = \\bar{x} = \\sum_{i=1}^n \\frac{x_i}{n} = 54.27$.\n",
    "- Mas dado que $\\hat{\\theta}$ é uma aproximação, então, qual a nossa incerteza em relação a $\\hat{\\theta}=54.27$?\n",
    "- Da mesma forma que $x = \\left( x_1, x_2, \\ldots, x_n \\right)$ é uma realização de $X$ (que é uma amostra teórica gerada a partir de $F$), $\\hat{\\theta}=t \\left( x \\right)=54.27$ também pode ser visto como uma realização de $\\hat{\\Theta}=t \\left( X \\right)$ (que representa os possíveis valores resultantes de $t \\left( . \\right)$ aplicados a possíveis amostras teóricas $X$ geradas a partir de $F$).\n",
    "- Então, $\\hat{\\Theta}$ pode assumir um intervalo de valores cuja a variação destes valores pode definir uma medida de incerteza.\n",
    "- Logo, aproveitando a primeira definição de inferência frequentista de que \"<mark><em>the accuracy of an observed estimate $\\hat{\\theta} = t \\left( x \\right)$ is the probabilistic accuracy of $\\hat{\\Theta} = t \\left( X \\right)$ as an estimator of $\\theta$</em></mark>\", podemos utilizar a variação de $\\hat{\\Theta}$ como uma medida da incerteza para a nossa estimativa $\\hat{\\theta}=54.27$.\n",
    "\n",
    "Mas como podemos medir esta incerteza?\n",
    "\n",
    "<blockquote>\n",
    "<mark>Bias and variance are familiar examples of frequentist inference</mark>. Define $\\mu$ to be the expectation of $\\hat{\\Theta} = t \\left( X \\right)$ under model $F \\rightarrow X$,\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\mu = E_F \\{ \\hat{\\Theta} \\} \\text{.}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Then the bias and variance attributed to estimate $\\hat{\\theta}$ of parameter $\\theta$ are\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\text{bias} = \\mu - \\theta \\enspace \\text{ and } \\enspace \\text{var} = E_F \\left\\{ \\left( \\hat{\\Theta} - \\mu \\right)^2 \\right\\}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Again, what keeps this from tautology is the attribution to the single number $\\hat{\\theta}$ of the probabilistic properties of $\\hat{\\Theta}$ following from model $F \\rightarrow X$.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "<mark>Frequentism is often defined with respect to “an infinite sequence of future trials”</mark>. We imagine hypothetical data sets $X^{(1)}, X^{(2)}, X^{(3)}, \\ldots$ generated by the same mechanism as $x$ providing corresponding values $\\hat{\\Theta}^{(1)}, \\hat{\\Theta}^{(2)}, \\hat{\\Theta}^{(3)}, \\ldots$ as in $\\hat{\\Theta} = t \\left( X \\right)$. <mark>The frequentist principle is then to attribute for $\\hat{\\theta}$ the accuracy properties of the ensemble of $\\hat{\\Theta}$ values</mark>.\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Frequentism in Practice\n",
    "\n",
    "A pergunta de antes ainda permanece, ou seja, como podemos medir, na prática, a variação de $\\hat{\\Theta}$ e utilizá-la como uma medida da incerteza para a nossa estimativa $\\hat{\\theta}=54.27$?\n",
    "\n",
    "<blockquote>\n",
    "Our working definition of frequentism is that <mark><em>the probabilistic properties of a procedure of interest are derived and then applied verbatim to the procedure’s output for the observed data</em>. This has an obvious defect: it requires calculating the properties of estimators $\\hat{\\Theta} = t \\left( X \\right)$ obtained from the true distribution $F$, even though $F$ is unknown</mark>. Practical frequentism uses a collection of more or less ingenious devices to circumvent the defect.\n",
    "\n",
    "<p>\n",
    "<strong><em>1. The plug-in principle.</em></strong> A simple formula relates the standard error of $\\bar{X} = \\sum_{i=1}^n \\frac{X_i}{n}$ to $\\text{var}_F \\left( X \\right)$, the variance of a single $X$ drawn from $F$,\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "se \\left( \\bar{X} \\right) = \\left[ \\frac{\\text{var}_F \\left( X \\right)}{n} \\right]^{\\frac{1}{2}} \\text{.} \\enspace \\enspace \\text{(2.8)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "But having observed $x = \\left( x_1, x_2, \\ldots, x_n \\right)$ we can estimate $\\text{var}_F \\left( X \\right)$ without bias by\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\hat{\\text{var}}_F = \\frac{\\sum_{i=1}^n \\left( x_i - \\bar{x} \\right)^2}{n-1} \\text{.} \\enspace \\enspace \\text{(2.9)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Plugging formula (2.9) into (2.8) gives $\\hat{se} = \\left[ \\frac{\\sum_{i=1}^n \\left( x_i - \\bar{x} \\right)^2}{\\left( n \\left( n-1 \\right) \\right)} \\right]^{\\frac{1}{2}}$, the usual estimate for the standard error of an average $\\bar{x}$. In other words, the frequentist accuracy estimate for $\\bar{x}$ is itself estimated from the observed data.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>\n",
    "\n",
    "Então, utilizando **(1)** a <font color=magenta>definição de inferência frequentista</font> de que \"<mark><em>the accuracy of an observed estimate $\\hat{\\theta} = t \\left( x \\right)$ is the probabilistic accuracy of $\\hat{\\Theta} = t \\left( X \\right)$ as an estimator of $\\theta$</em></mark>\" e utilizando **(2)** o *<font color=magenta>plug-in principle</font>* temos que:\n",
    "- **(1a)**: pelo Teorema Central do Limite (*Central Limit Theorem - CLT*), sob certas condições ([mais detalhes aqui](https://fmafonseca.github.io/statistical-thinking-data-science/001.teorema-central-do-limite.html)), a distribuição das <font color=blue>médias das amostras</font> (*<font color=blue>sample means</font>*) $\\bar{X}$ é aproximadamente normal (*nearly normal*), centrada na <font color=orange>média da população</font> (*<font color=orange>population mean</font>*) $\\mu_{pop}$, e com um <font color=blue>desvio padrão</font> (*<font color=blue>standard deviation</font>*) $SE$ igual ao <font color=orange>desvio padrão da população</font> (*<font color=orange>population standard deviation</font>*) $\\sigma$ dividido pela raiz quadrada do <font color=gray>tamanho das amostras</font> (*<font color=gray>samples size</font>*) $n$.\n",
    "\n",
    "$$\n",
    "\\bar{X} \\sim \\mathcal{N}\\left(mean=\\mu_{pop}, SE=\\frac{\\sigma}{\\sqrt{n}}\\right)\n",
    "$$\n",
    "\n",
    "- **(1b)**: fazendo a ligação entre o Teorema Central do Limite (*Central Limit Theorem - CLT*) e o exemplo do livro, temos que:\n",
    "  - $\\bar{X}$ está para $\\hat{\\Theta}$, assim como,\n",
    "  - $\\mu_{pop}$ está para $\\theta = E_F \\{ X \\}$, assim como,\n",
    "  - $SE$ está para $se \\left( \\bar{X} \\right)$, logo, temos como propriedades probabilísticas para $\\hat{\\Theta}$ o seguinte:\n",
    "\n",
    "$$\n",
    "\\hat{\\Theta} \\sim \\mathcal{N}\\left(mean=\\theta=E_F\\{X\\}, \\enspace SE=\\frac{\\sigma_F}{\\sqrt{n}}=\\left[ \\frac{\\text{var}_F \\left( X \\right)}{n} \\right]^{\\frac{1}{2}}\\right)\n",
    "$$\n",
    "\n",
    "- **(1c)**: e pela <font color=magenta>definição de inferência frequentista</font>, então, podemos assumir que a incerteza da estimativa $\\hat{\\theta}=54.27$ será medida pelo erro padrão (*standard deviation*) $SE=\\frac{\\sigma_F}{\\sqrt{n}}$ de $\\hat{\\Theta}$.\n",
    "\n",
    "- **(2)** : e, finalmente, pelo *<font color=magenta>plug-in principle</font>* podemos estimar o desvio padrão $\\sigma_F$ de $F$ através do desvio padrão $s$ do que foi observado via $x = \\left( x_1, x_2, \\ldots, x_n \\right)$. Que é a mesma coisa do que estimar $\\text{var}_F \\left( X \\right)$ através de $\\hat{\\text{var}}_F$ (equação 2.9 do livro).\n",
    "\n",
    "É deste modo que chegamos em\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} \\pm \\hat{se} \\enspace \\Rightarrow \\enspace 54.27 \\pm 0.94\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of glr measurements = 211\n",
      "Mean of glr measurements = 54.27\n",
      "Estimated standard error for mean of glr measurements = 0.94\n"
     ]
    }
   ],
   "source": [
    "n = len(gfr_df.index)\n",
    "mean_glr = gfr_df.glr.mean()\n",
    "estimated_se_mean_glr = gfr_df.glr.std() / np.sqrt(n)\n",
    "\n",
    "print(\"Number of glr measurements = {0}\".format(n))\n",
    "print(\"Mean of glr measurements = {0:.2f}\".format(mean_glr))\n",
    "print(\"Estimated standard error for mean of glr measurements = {0:.2f}\".format(estimated_se_mean_glr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<strong><em>4. Simulation and the bootstrap.</em></strong> <mark>Modern computation has opened up the possibility of numerically implementing the “infinite sequence of future trials” definition, except for the infinite part</mark>. An estimate $\\hat{F}$ of $F$, perhaps the MLE, is found, and values $\\hat{\\Theta}^{(k)} = t\\left( X^{(k)} \\right)$ simulated from $\\hat{F}$ for $k=1, 2, \\ldots, B$, say $B=1000$. <mark>The empirical standard deviation of the $\\hat{\\Theta}$s is then the frequentist estimate of standard error for $\\hat{\\theta} = t \\left( x \\right)$</mark>, and similarly with other measures of accuracy.\n",
    "\n",
    "<p>\n",
    "This is a good description of the bootstrap, Chapter 10. (Notice that here the plugging-in, of $\\hat{F}$ for $F$, comes first rather than at the end of the process.) The classical methods 1–3 above are restricted to estimates $\\hat{\\theta} = t \\left( x \\right)$ that are smoothly defined functions of various sample means. Simulation calculations remove this restriction. Table 2.1 shows three “location” estimates for the <strong><font color=green>gfr</font></strong> data, the mean, the $25\\%$ Winsorized mean, and the median, along with their standard errors, the last two computed by the bootstrap. A happy feature of computer-age statistical inference is the tremendous expansion of useful and usable statistics $t \\left( x \\right)$ in the statistician’s working toolbox, the <strong><font color=green>lowess</font></strong> algorithm in Figures 1.2 and 1.3 providing a nice example.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from scipy.stats import mstats\n",
    "\n",
    "winsorized_limit = 0.25\n",
    "\n",
    "# calculates values Θ̂ (k)=t(X(k)) simulated from F̂ for k=1,2,…,B, say B=1000\n",
    "#    for t(.) = the 25% Winsorized mean, and\n",
    "#        t(.) = the median\n",
    "glr_bootstrap_metrics_df = pd.DataFrame(columns=['replication', 'winsorized_mean', 'median'])\n",
    "replicates = 1000\n",
    "for rep in range(replicates):\n",
    "    # \"generates an estimate F̂ of F via bootstrap\"\n",
    "    bootstrap_idxs = np.random.choice(n, n)\n",
    "    new_gfr_df = gfr_df.iloc[bootstrap_idxs]\n",
    "    \n",
    "    # \"calculates Θ̂ (k)=t(X(k)) simulated from F̂\"\n",
    "    \n",
    "    # for t(.) = the 25% Winsorized mean, and\n",
    "    winsorized_glr = mstats.winsorize(new_gfr_df.glr, limits=[winsorized_limit, winsorized_limit])\n",
    "    winsorized_mean_glr = np.mean(winsorized_glr)\n",
    "    # for t(.) = the median\n",
    "    median_glr = new_gfr_df.glr.median()\n",
    "    \n",
    "    df_row = pd.DataFrame({'replication': [rep], 'winsorized_mean': [winsorized_mean_glr], 'median': [median_glr]})\n",
    "    glr_bootstrap_metrics_df = pd.concat([glr_bootstrap_metrics_df, df_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<strong>Table 2.1</strong> <em>Three estimates of location for the <strong><font color=green>gfr</font></strong> data, and their estimated standard errors; last two standard errors using the bootstrap, $B=1000$</em>.\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Standard Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.27</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25% winsorized mean</th>\n",
       "      <td>52.81</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>52.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Estimate  Standard Error\n",
       "mean                    54.27            0.94\n",
       "25% winsorized mean     52.81            0.90\n",
       "median                  52.00            0.86"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats\n",
    "\n",
    "# 25% winsorized mean and standard error\n",
    "winsorized_glr = mstats.winsorize(gfr_df.glr, limits=[winsorized_limit, winsorized_limit])\n",
    "winsorized_mean_glr = np.mean(winsorized_glr)\n",
    "empirical_std = bs.bootstrap(np.array(glr_bootstrap_metrics_df['winsorized_mean']), stat_func=bs_stats.std)\n",
    "estimated_se_winsorized_mean_glr = empirical_std.value\n",
    "\n",
    "# median and standard error\n",
    "median_glr = gfr_df.glr.median()\n",
    "empirical_std = bs.bootstrap(np.array(glr_bootstrap_metrics_df['median']), stat_func=bs_stats.std)\n",
    "estimated_se_median_glr = empirical_std.value\n",
    "\n",
    "# create Table 2.1\n",
    "estimates_column = np.round([mean_glr, winsorized_mean_glr, median_glr], decimals=2)\n",
    "se_column = np.round([estimated_se_mean_glr, estimated_se_winsorized_mean_glr, estimated_se_median_glr], decimals=2)\n",
    "table_2_1 = pd.DataFrame(\n",
    "    {'Estimate': estimates_column, 'Standard Error': se_column},\n",
    "    index = ['mean', '25% winsorized mean', 'median']\n",
    ")\n",
    "table_2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<strong><em>5. Pivotal statistics.</em></strong> <mark>A pivotal statistic $\\hat{\\theta} = t \\left( x \\right)$ is one whose distribution does not depend upon the underlying probability distribution $F$. In such a case the theoretical distribution of $\\hat{\\Theta} = t\\left( X \\right)$ applies exactly to $\\hat{\\theta}$, removing the need for devices 1–4 above</mark>. The classic example concerns Student’s two-sample $t$-test.\n",
    "\n",
    "<p>\n",
    "In a two-sample problem the statistician observes two sets of numbers,\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "x_1 = \\left( x_{11}, x_{12}, \\ldots, x_{1n_1} \\right) \\enspace x_2 = \\left( x_{21}, x_{22}, \\ldots, x_{2n_2} \\right) \\text{,} \\enspace \\enspace \\enspace \\text{(2.11)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "and wishes to test the <em>null hypothesis</em> that they come from the same distribution (as opposed to, say, the second set tending toward larger values than the first). It is assumed that the distribution $F_1$ for $x_1$ is <em>normal</em>, or <em>Gaussian</em>,\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "X_{1i} \\overset{ind}{\\sim} \\mathcal{N}\\left(\\mu_1, \\sigma^2 \\right), \\enspace \\enspace i=1,2,\\ldots,n_1, \\enspace \\enspace \\enspace \\text{(2.12)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "the notation indicating $n_1$ independent draws from a normal distribution with expectation $\\mu_1$ and variance $\\sigma^2$. Likewise\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "X_{2i} \\overset{ind}{\\sim} \\mathcal{N}\\left(\\mu_2, \\sigma^2 \\right), \\enspace \\enspace i=1,2,\\ldots,n_2. \\enspace \\enspace \\enspace \\text{(2.13)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "We wish to test the null hypothesis\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "H_0 : \\mu_1 = \\mu_2. \\enspace \\enspace \\enspace \\text{(2.14)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "The obvious test statistic $\\hat{\\theta} = \\bar{x}_2 - \\bar{x}_1$, the difference of the means, has distribution\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\hat{\\theta} \\sim \\mathcal{N}\\left(0, \\sigma^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right) \\right) \\enspace \\enspace \\enspace \\text{(2.15)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "under $H_0$. We <mark>could plug in</mark> the unbiased estimate of $\\sigma^2$,\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^{n_1} \\left( x_{1i} - \\bar{x}_1 \\right)^2 + \\sum_{i=1}^{n_2} \\left( x_{2i} - \\bar{x}_2 \\right)^2}{n_1+n_2-2} \\enspace \\enspace \\enspace \\text{(2.16)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A equação **(2.15)** vem do *Lemma 6* descrito no relatório *Mathematical Justifcation of Introductory Hypothesis Tests and Development of Reference Materials* de *Jennifer L. Loveland*:\n",
    "\n",
    "<blockquote>\n",
    "<strong>LEMMA 6</strong>. <em>If $X_1,X_2,\\ldots,X_n$ and $Y_1,Y_2,\\ldots,Y_m$ are independent with $X_i \\sim \\mathcal{N}\\left( \\mu_X,\\sigma^2 \\right)$ and $Y_i \\sim \\mathcal{N}\\left( \\mu_Y,\\sigma^2 \\right)$ then</em>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\bar{X} - \\bar{Y} \\sim \\mathcal{N}\\left( \\mu_X - \\mu_Y, \\sigma^2 \\left( \\frac{1}{n} + \\frac{1}{m} \\right) \\right)\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Loveland, Jennifer L., \"Mathematical Justifcation of Introductory Hypothesis Tests and Development of Reference Materials\" (2011). All Graduate Plan B and other Reports. 14. https://digitalcommons.usu.edu/gradreports/14</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando com a explicação de **Pivotal statistics** como um dos mecanismos para viabilizar, na prática, a **inferência frequentista** ...\n",
    "\n",
    "<blockquote>\n",
    "but Student provided a more elegant solution: instead of $\\hat{\\theta}$, we test $H_0$ using the two-sample $t$-statistic\n",
    "\n",
    "<p>\n",
    "$$\n",
    "t = \\frac{\\bar{x}_2 - \\bar{x}_1}{\\hat{sd}} \\enspace \\enspace \\text{where } \\hat{sd} = \\hat{\\sigma} \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)^{1/2} \\enspace \\enspace \\enspace \\text{(2.17)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<mark>Under $H_0$, $t$ is pivotal, having the same distribution (Student’s $t$ distribution with $n_1 + n_2 - 2$ degrees of freedom), no matter what the value of the “nuisance parameter\" $\\sigma$.</mark>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A equação **(2.17)** e o fato de que a estatística $t$ segue uma distribuição $t$ com $n_1 + n_2 - 2$ graus de liberdade (ou seja, segue uma distribuição que não depende do parâmetro $\\sigma$ e, por isto, a estatística é considerada *pivotal*) vem da *Definition 11* e do *Theorem 22* descrito no relatório *Mathematical Justifcation of Introductory Hypothesis Tests and Development of Reference Materials* de *Jennifer L. Loveland*:\n",
    "\n",
    "<blockquote>\n",
    "<strong>DEFINITION 11</strong>. <em>If $X_1,X_2,\\ldots,X_n$ are random variables, let</em>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\bar{X} = \\frac{\\sum_{i=1}^{n} X_i}{n} \\enspace \\enspace \\text{and} \\enspace \\enspace S = \\frac{\\sum_{i=1}^{n} \\left(X_i - \\bar{X} \\right)}{n-1}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<strong>THEOREM 22</strong>. <em>If $X_1,X_2,\\ldots,X_n$ and $Y_1,Y_2,\\ldots,Y_m$ are independent with $X_i \\sim \\mathcal{N}\\left( \\mu_X,\\sigma^2_X \\right)$ and $Y_i \\sim \\mathcal{N}\\left( \\mu_Y,\\sigma^2_Y \\right)$, then the statistic</em>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "T = \\frac{\\left( \\bar{X} - \\bar{Y} \\right) - \\left( \\mu_X - \\mu_Y \\right)}{S_p \\sqrt{\\frac{1}{n} + \\frac{1}{m}}} \\enspace \\enspace \\text{where } S_p = \\sqrt{\\frac{\\left(n-1\\right) S^2_X + \\left(m-1\\right) S^2_Y}{n+m-2}}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<em>has a $t$ distribution with $n+m-2$ degrees of freedom.</em>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Loveland, Jennifer L., \"Mathematical Justifcation of Introductory Hypothesis Tests and Development of Reference Materials\" (2011). All Graduate Plan B and other Reports. 14. https://digitalcommons.usu.edu/gradreports/14</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando com a explicação de **Pivotal statistics** como um dos mecanismos para viabilizar, na prática, a **inferência frequentista** ...\n",
    "\n",
    "<blockquote>\n",
    "For $n_1 + n_2 - 2 = 70$, as in the leukemia example (1.5)–(1.6), Student’s distribution gives\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\text{Pr}_{H_0} \\{-1.99 \\leq t \\leq 1.99 \\} = 0.95 \\enspace \\enspace \\enspace \\text{(2.18)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability(-1.99 <= t <= 1.99 | dof=70) = 0.95 (95%)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as st\n",
    "\n",
    "# t distribution with 70 degrees of freedom\n",
    "t_distribution_70dof = st.t(df=70)\n",
    "\n",
    "probability = 1.0 - 2*t_distribution_70dof.cdf(x=-1.99)\n",
    "\n",
    "print(\"Probability(-1.99 <= t <= 1.99 | dof=70) = {0:.2f} ({1:.0f}%)\".format(probability, probability*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "The hypothesis test that rejects $H_0$ if $|t|$ exceeds $1.99$ has probability exactly $0.05$ of mistaken rejection. Similarly,\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\bar{x}_2 - \\bar{x}_1 \\pm 1.99 \\hat{sd} \\enspace \\enspace \\enspace \\text{(2.19)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "is an exact $0.95$ <em>confidence interval</em> for the difference $\\mu_2 - \\mu_1$, covering the true value in $95\\%$ of repetitions of probability model (2.12)-(2.13).<sup>6</sup>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<sup>6</sup> <sub>Occasionally, one sees frequentism defined in careerist terms, e.g., <mark>“A statistician who always rejects null hypotheses at the $95\\%$ level will over time make only $5\\%$ errors of the first kind.” This is not a comforting criterion for the statistician’s clients, who are interested in their own situations, not everyone else’s. Here we are only assuming hypothetical repetitions of the specific problem at hand.</mark></sub>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Frequentist Optimality\n",
    "\n",
    "<blockquote>\n",
    "The popularity of frequentist methods reflects their <mark>relatively modest mathematical modeling assumptions: only a probability model $F$ (more exactly a family of probabilities, Chapter 3) and an algorithm of choice $t \\left(x\\right)$. This flexibility is also a defect in that the principle of frequentist correctness doesn’t help with the choice of algorithm</mark>. Should we use the sample mean to estimate the location of the <strong><font color=green>gfr</font></strong> distribution? Maybe the $25\\%$ Winsorized mean would be better, as Table 2.1 suggests.\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>\n",
    "\n",
    "No caso da minha reprodução da **Tabela 2.1**, uma vez que os números estão um pouco diferentes do exemplo do livro, então, seria mais correto dizer, no meu contexto, ... *\"Should we use the sample mean to estimate the location of the <strong><font color=green>gfr</font></strong> distribution? Maybe the **median** would be better, as Table 2.1 suggests.\"* ... uma vez que a mediana está com um erro padrão menor do que os demais estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Standard Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.27</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25% winsorized mean</th>\n",
       "      <td>52.81</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>52.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Estimate  Standard Error\n",
       "mean                    54.27            0.94\n",
       "25% winsorized mean     52.81            0.90\n",
       "median                  52.00            0.86"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "In the same spirit, the Neyman–Pearson lemma provides an optimum hypothesis-testing algorithm. This is perhaps the most elegant of frequentist constructions. In its simplest formulation, the NP lemma assumes we are trying to decide between two possible probability density functions for the observed data $x$, a null hypothesis density $f_0\\left(x\\right)$ and an alternative density $f_1\\left(x\\right)$. A testing rule $t\\left(x\\right)$ says which choice, $0$ or $1$, we will make having observed data $x$. Any such rule has two associated frequentist error probabilities: choosing $f_1$ when actually $f_0$ generated $x$, and vice versa,\n",
    "\n",
    "<p>\n",
    "$$\n",
    "\\alpha = \\text{Pr}_{f_0} \\{t(x)=1\\},\n",
    "$$\n",
    "$$\n",
    "\\beta = \\text{Pr}_{f_1} \\{t(x)=0\\}.\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Let $L(x)$ be the <em>likelihood ratio</em>,\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "$$\n",
    "L(x) = \\frac{f_1\\left(x\\right)}{f_0\\left(x\\right)}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio(x, f1_density, f0_density):\n",
    "    return np.prod(f1_density.pdf(x)) / np.prod(f0_density.pdf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "and define the testing rule $t_c(x)$ by\n",
    "\n",
    "<p>\n",
    "$$\n",
    "t_c(x) = \\left\\{ \\begin{array}{ll} 1\\enspace\\text{if log } L(x) \\ge c\\\\ 0\\enspace\\text{if log } L(x) \\lt c.\\end{array} \\right.\n",
    "$$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neyman_Pearson_testing_rule(x, cutoff, f0_density, f1_density):\n",
    "    lr = likelihood_ratio(x, f1_density, f0_density)\n",
    "    llr = np.log(lr)\n",
    "    \n",
    "    if llr >= cutoff:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<strong>Figure 2.2</strong> Neyman–Pearson alpha–beta curve for $f_0 \\sim \\mathcal{N} \\left(0,1\\right), \\enspace f_1 \\sim \\mathcal{N} \\left(0.5,1\\right)$, and sample size $n=10$. Red dots correspond to cutoffs $c=0.8,0.6,0.4,\\ldots,-0.4$.\n",
    "\n",
    "<p>\n",
    "Figure 2.2 graphs $\\left(\\alpha_c,\\beta_c\\right)$ as a function of the cutoff $c$, for the case where $x=\\left(x_1,x_2,\\ldots,x_{10}\\right)$ is obtained by independent sampling from a normal distribution, $\\mathcal{N}\\sim\\left(0,1\\right)$ for $f_0$ versus $\\mathcal{N}\\sim\\left(0.5,1\\right)$ for $f_1$. The NP lemma says that any rule not of form (2.22) must have its $\\left(\\alpha,\\beta\\right)$ point lying above the curve.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<small>(Fonte: <em>Efron, B., & Hastie, T. (2016). Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. Cambridge: Cambridge University Press.</em>)</small>\n",
    "</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_simulation(cutoff, f0_density, f1_density, sample_size, replicates):\n",
    "    NP_test_results = []\n",
    "    \n",
    "    for _ in range(replicates):\n",
    "        x = f0_density.rvs(size=sample_size)\n",
    "        test = Neyman_Pearson_testing_rule(x, cutoff, f0_density, f1_density)\n",
    "        NP_test_results.append(test)\n",
    "    \n",
    "    return np.sum(NP_test_results) / float(replicates)\n",
    "\n",
    "def beta_simulation(cutoff, f0_density, f1_density, sample_size, replicates):\n",
    "    NP_test_results = []\n",
    "    \n",
    "    for _ in range(replicates):\n",
    "        x = f1_density.rvs(size=sample_size)\n",
    "        test = Neyman_Pearson_testing_rule(x, cutoff, f0_density, f1_density)\n",
    "        NP_test_results.append(test)\n",
    "    \n",
    "    return (replicates - np.sum(NP_test_results)) / float(replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f0_density = st.norm(loc=0, scale=1)\n",
    "f1_density = st.norm(loc=0.5, scale=1)\n",
    "\n",
    "sample_size = 10\n",
    "replicates = 12000\n",
    "\n",
    "cutoffs = []\n",
    "alphas_simulated = []\n",
    "betas_simulated = []\n",
    "for cutoff in np.arange(3.2, -3.6, -0.4):\n",
    "    alpha_ = alpha_simulation(cutoff, f0_density, f1_density, sample_size, replicates)\n",
    "    beta_ = beta_simulation(cutoff, f0_density, f1_density, sample_size, replicates)\n",
    "    \n",
    "    cutoffs.append(cutoff)\n",
    "    alphas_simulated.append(alpha_)\n",
    "    betas_simulated.append(beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Reproducing Figure 2.2 from simulation results.\n",
    "plt.xlabel('$\\\\alpha$')\n",
    "plt.ylabel('$\\\\beta$')\n",
    "plt.xlim(-0.1, 1.05)\n",
    "plt.ylim(-0.1, 1.05)\n",
    "plt.axvline(x=0, color='b', linestyle='--')\n",
    "plt.axvline(x=1, color='b', linestyle='--')\n",
    "plt.axhline(y=0, color='b', linestyle='--')\n",
    "plt.axhline(y=1, color='b', linestyle='--')\n",
    "figure_2_2 = plt.plot(alphas_simulated, betas_simulated, 'ro', alphas_simulated, betas_simulated, 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Register.StartupHook(\"TeX Jax Ready\",function () {\n",
    "  MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{\n",
    "    cancel: [\"Extension\",\"cancel\"],\n",
    "    bcancel: [\"Extension\",\"cancel\"],\n",
    "    xcancel: [\"Extension\",\"cancel\"],\n",
    "    cancelto: [\"Extension\",\"cancel\"]\n",
    "  });\n",
    "});\n",
    "</script>\n",
    "\n",
    "Apesar do gráfico acima ter ficado muito parecido com o do livro existem algumas diferenças para os valores de $\\alpha$ e $\\beta$ para o mesmo valor de $c$, por exemplo:\n",
    "- enquanto que no livro temos $\\alpha=0.10$ e $\\beta=0.38$ para $c=0.4$\n",
    "- na simulação acima tivemos $\\alpha=0.15$ e $\\beta=0.30$ para $c=0.4$.\n",
    "\n",
    "Então, ao invés de reproduzir a Figura 2.2 através de simulação vamos tentar reproduzi-la analiticamente encontrando as fórmulas para calcular $\\alpha$ e $\\beta$.\n",
    "\n",
    "Uma vez que $f_0 \\sim \\mathcal{N} \\left(0,1\\right)$ e $f_1 \\sim \\mathcal{N} \\left(0.5,1\\right)$ são funções densidade de probabilidade (*probability density functions*) de uma distribuição Normal, então, temos que:\n",
    "\n",
    "$$\n",
    "f\\left(x \\;\\middle\\vert\\; \\mu, \\sigma^2 \\right) = \\prod_{i = 1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{\\left(x_i-\\mu\\right)^2}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que a razão de verossimilhança (*likelihood ratio*) $L(x)$ é dada por\n",
    "\n",
    "$$\n",
    "L(x) = \\frac{f_1\\left(x\\right)}{f_0\\left(x\\right)}\n",
    "$$\n",
    "\n",
    "então, temos:\n",
    "\n",
    "$$\n",
    "L(x) = \\frac{f_1\\left(x\\;\\middle\\vert\\; \\mu_1, \\sigma^2\\right)}{f_0\\left(x\\;\\middle\\vert\\; \\mu_0, \\sigma^2\\right)} = \\frac{\\prod_{i = 1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{\\left(x_i-\\mu_1\\right)^2}{2\\sigma^2}}}{\\prod_{i = 1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{\\left(x_i-\\mu_0\\right)^2}{2\\sigma^2}}}\n",
    "$$\n",
    "\n",
    "Logo, realizando algumas simplificações algébricas (como abaixo), teremos:\n",
    "\n",
    "$$\n",
    "L(x) = \\frac{\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^n e^{-\\frac{\\sum_{i = 1}^{n} \\left(x_i-\\mu_1\\right)^2}{2\\sigma^2}}}{\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^n e^{-\\frac{\\sum_{i = 1}^{n} \\left(x_i-\\mu_0\\right)^2}{2\\sigma^2}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= e^{\\frac{-\\sum_{i = 1}^{n} \\left(x_i-\\mu_1\\right)^2 + \\sum_{i = 1}^{n} \\left(x_i-\\mu_0\\right)^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= e^{\\frac{-\\sum_{i = 1}^{n} \\left(x_i^2 -2x_i\\mu_1 + \\mu_1^2\\right) + \\sum_{i = 1}^{n} \\left(x_i^2 -2x_i\\mu_0 + \\mu_0^2\\right)}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= e^{\\frac{-\\sum_{i = 1}^{n}x_i^2 + 2\\mu_1\\sum_{i = 1}^{n}x_i - \\sum_{i = 1}^{n}\\mu_1^2 + \\sum_{i = 1}^{n}x_i^2 - 2\\mu_0\\sum_{i = 1}^{n}x_i + \\sum_{i = 1}^{n}\\mu_0^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= e^{\\frac{2\\left(\\mu_1-\\mu_0\\right)\\sum_{i = 1}^{n}x_i + n\\left(\\mu_0^2-\\mu_1^2\\right)}{2\\sigma^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, se\n",
    "\n",
    "$$\n",
    "t_c(x) = \\left\\{ \\begin{array}{ll} 1\\enspace\\text{if log } L(x) \\ge c\\\\ 0\\enspace\\text{if log } L(x) \\lt c.\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "para $\\text{log } L(x) \\ge c$ temos:\n",
    "\n",
    "$$\n",
    "\\text{log } \\left( e^{\\frac{2\\left(\\mu_1-\\mu_0\\right)\\sum_{i = 1}^{n}x_i + n\\left(\\mu_0^2-\\mu_1^2\\right)}{2\\sigma^2}} \\right) \\ge c\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{2\\left(\\mu_1-\\mu_0\\right)\\sum_{i = 1}^{n}x_i + n\\left(\\mu_0^2-\\mu_1^2\\right)}{2\\sigma^2} \\ge c\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^{n}x_i \\ge \\frac{2c\\sigma^2 - n\\left(\\mu_0^2-\\mu_1^2\\right)}{2\\left(\\mu_1-\\mu_0\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^{n}x_i \\ge \\frac{2c\\sigma^2}{2\\left(\\mu_1-\\mu_0\\right)} - \\frac{n\\left(\\mu_0^2-\\mu_1^2\\right)}{2\\left(\\mu_1-\\mu_0\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^{n}x_i \\ge \\frac{c\\sigma^2}{\\left(\\mu_1-\\mu_0\\right)} - \\frac{n\\left(\\mu_0^2-\\mu_1^2\\right)}{2\\left(\\mu_1-\\mu_0\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^{n}x_i \\ge \\frac{c\\sigma^2}{\\left(\\mu_1-\\mu_0\\right)} + \\frac{n\\left(\\mu_1^2-\\mu_0^2\\right)}{2\\left(\\mu_1-\\mu_0\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^{n}x_i \\ge \\frac{c\\sigma^2}{\\left(\\mu_1-\\mu_0\\right)} + \\frac{n\\left(\\mu_1-\\mu_0\\right)\\left(\\mu_1+\\mu_0\\right)}{2\\left(\\mu_1-\\mu_0\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^{n}x_i \\ge \\frac{c\\sigma^2}{\\left(\\mu_1-\\mu_0\\right)} + \\frac{n\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left(\\frac{1}{n}\\right) \\sum_{i = 1}^{n}x_i \\ge \\left(\\frac{1}{n}\\right) \\left( \\frac{c\\sigma^2}{\\left(\\mu_1-\\mu_0\\right)} + \\frac{n\\left(\\mu_1+\\mu_0\\right)}{2}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\sum_{i = 1}^{n}x_i}{n} \\ge \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{x} \\ge \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{x} \\ge k \\text{, onde } k = \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$\n",
    "\n",
    "Logo, o teste passa a ser:\n",
    "\n",
    "$$\n",
    "t_c(x) = \\left\\{ \\begin{array}{ll} 1\\enspace\\text{if } \\bar{x} \\ge k\\\\ 0\\enspace\\text{if } \\bar{x} \\lt k.\\end{array} \\right. \\enspace \\enspace \\text{, onde } k = \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcularmos $\\alpha$ e $\\beta$, sabemos que:\n",
    "\n",
    "$$\n",
    "\\alpha = \\text{Pr}_{f_0} \\{t(x)=1\\},\n",
    "$$\n",
    "$$\n",
    "\\beta = \\text{Pr}_{f_1} \\{t(x)=0\\}.\n",
    "$$\n",
    "\n",
    "então,\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll} \\alpha = \\text{Pr}_{f_0} \\{\\bar{x} \\ge k\\},\\\\ \\beta = \\text{Pr}_{f_1} \\{\\bar{x} \\lt k\\}.\\end{array} \\enspace \\enspace \\text{ onde } k = \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logo, \n",
    "\n",
    "$$\n",
    "\\alpha = \\text{Pr}_{f_0} \\{\\bar{x} \\ge k\\} = \\text{Pr}_{f_0} \\{\\bar{x} - \\mu_0 \\ge k - \\mu_0\\}\n",
    "$$\n",
    "\n",
    "pelo Teorema Central do Limite (*Central Limit Theorem - CLT*), sob certas condições ([mais detalhes aqui](https://fmafonseca.github.io/statistical-thinking-data-science/001.teorema-central-do-limite.html)), sabemos que:\n",
    "\n",
    "$$\n",
    "\\bar{X} \\sim \\mathcal{N}\\left(mean=\\mu_{pop}, SE=\\frac{\\sigma}{\\sqrt{n}}\\right)\n",
    "$$\n",
    "\n",
    "então, dividindo ambos os lados da inequação por $\\frac{\\sigma}{\\sqrt{n}}$ teremos:\n",
    "\n",
    "$$\n",
    "\\alpha = \\text{Pr}_{f_0} \\left\\{\\frac{\\bar{x} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\ge \\frac{k - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\\right\\}\n",
    "$$\n",
    "\n",
    "uma vez que o termo $\\frac{\\bar{x} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}$ representa a distância em desvios padrão (*standard deviations*) da média $\\mu_0$, então, podemos interpretar este termo como o escore z (*z score*), logo\n",
    "\n",
    "$$\n",
    "\\alpha = \\text{Pr}_{f_0} \\left\\{\\text{z-score} \\ge \\frac{k - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\\right\\} \\enspace \\enspace \\text{ onde } k = \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$\n",
    "\n",
    "além disto, sabemos que os valores de escore z (*z score*) são distribuídos de acordo com a distribuição z (*z distribution*) que é a distribuição normal padrão, ou seja, $\\text{z-score} \\sim \\mathcal{N}(\\mu=0,\\sigma=1)$, então"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_calculation(cutoff, m_0, m_1, variance, sample_size):\n",
    "    c = cutoff\n",
    "    n = sample_size\n",
    "    sigma = np.sqrt(variance)\n",
    "    \n",
    "    k = (c*variance)/(n*(m_1-m_0)) + (m_1+m_0)/2.0\n",
    "    \n",
    "    z_alpha = (k-m_0)/(sigma/np.sqrt(n))\n",
    "    \n",
    "    # Pr{z_score >= z_alpha}\n",
    "    return 1.0 - st.norm(loc=0, scale=1).cdf(z_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o mesmo raciocíncio para $\\beta$ temos:\n",
    "\n",
    "$$\n",
    "\\beta = \\text{Pr}_{f_1} \\{\\bar{x} \\lt k\\} = \\text{Pr}_{f_1} \\{\\bar{x} - \\mu_1 \\lt k - \\mu_1\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta = \\text{Pr}_{f_1} \\left\\{\\frac{\\bar{x} - \\mu_1}{\\frac{\\sigma}{\\sqrt{n}}} \\lt \\frac{k - \\mu_1}{\\frac{\\sigma}{\\sqrt{n}}}\\right\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta = \\text{Pr}_{f_1} \\left\\{\\text{z-score} \\lt \\frac{k - \\mu_1}{\\frac{\\sigma}{\\sqrt{n}}}\\right\\} \\enspace \\enspace \\text{ onde } k = \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_calculation(cutoff, m_0, m_1, variance, sample_size):\n",
    "    c = cutoff\n",
    "    n = sample_size\n",
    "    sigma = np.sqrt(variance)\n",
    "    \n",
    "    k = (c*variance)/(n*(m_1-m_0)) + (m_1+m_0)/2.0\n",
    "    \n",
    "    z_beta = (k-m_1)/(sigma/np.sqrt(n))\n",
    "    \n",
    "    # Pr{z_score < z_beta}\n",
    "    return st.norm(loc=0, scale=1).cdf(z_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "alphas_calculated = []\n",
    "betas_calculated = []\n",
    "for cutoff in cutoffs:\n",
    "    alpha_ = alpha_calculation(cutoff, 0.0, 0.5, 1.0, sample_size)\n",
    "    beta_ = beta_calculation(cutoff, 0.0, 0.5, 1.0, sample_size)\n",
    "    \n",
    "    alphas_calculated.append(alpha_)\n",
    "    betas_calculated.append(beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reproducing Figure 2.2 from calculation results.\n",
    "plt.xlabel('$\\\\alpha$')\n",
    "plt.ylabel('$\\\\beta$')\n",
    "plt.xlim(-0.1, 1.05)\n",
    "plt.ylim(-0.1, 1.05)\n",
    "plt.axvline(x=0, color='b', linestyle='--')\n",
    "plt.axvline(x=1, color='b', linestyle='--')\n",
    "plt.axhline(y=0, color='b', linestyle='--')\n",
    "plt.axhline(y=1, color='b', linestyle='--')\n",
    "figure_2_2 = plt.plot(alphas_calculated, betas_calculated, 'ro', alphas_calculated, betas_calculated, 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff</th>\n",
       "      <th>simulated alpha</th>\n",
       "      <th>simulated beta</th>\n",
       "      <th>calculated alpha</th>\n",
       "      <th>calculated beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cutoff  simulated alpha  simulated beta  calculated alpha  calculated beta\n",
       "0      3.2             0.00            0.89              0.00             0.89\n",
       "1      2.8             0.01            0.84              0.01             0.84\n",
       "2      2.4             0.01            0.76              0.01             0.77\n",
       "3      2.0             0.02            0.68              0.02             0.68\n",
       "4      1.6             0.03            0.59              0.04             0.59\n",
       "5      1.2             0.06            0.48              0.06             0.49\n",
       "6      0.8             0.09            0.39              0.10             0.39\n",
       "7      0.4             0.16            0.29              0.15             0.30\n",
       "8      0.0             0.21            0.22              0.21             0.21\n",
       "9     -0.4             0.29            0.15              0.30             0.15\n",
       "10    -0.8             0.39            0.10              0.39             0.10\n",
       "11    -1.2             0.48            0.06              0.49             0.06\n",
       "12    -1.6             0.59            0.04              0.59             0.04\n",
       "13    -2.0             0.68            0.02              0.68             0.02\n",
       "14    -2.4             0.77            0.01              0.77             0.01\n",
       "15    -2.8             0.84            0.01              0.84             0.01\n",
       "16    -3.2             0.90            0.00              0.89             0.00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'cutoff': np.round(cutoffs, decimals=2), \n",
    "    'simulated alpha': np.round(alphas_simulated, decimals=2),\n",
    "    'simulated beta': np.round(betas_simulated, decimals=2),\n",
    "    'calculated alpha': np.round(alphas_calculated, decimals=2),\n",
    "    'calculated beta': np.round(betas_calculated, decimals=2)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dúvida no site do Livro e no Cross Validated\n",
    "\n",
    "Devido à diferença entre a minha simulação e o livro para os valores de $\\alpha$ e $\\beta$, postei a seguinte questão no Cross Validated:\n",
    "\n",
    "https://stats.stackexchange.com/q/383845/231794\n",
    "\n",
    "Após um tempo sem respostas no site Cross Validated, postei a mesma questão no fórum de discussão do próprio livro e tive a grata surpresa de ser respondido pelo professor **Trevor Hastie** (um dos autores do livro):\n",
    "\n",
    "https://disqus.com/home/discussion/computeragestatisticalinference/computer_age_statistical_inference_algorithms_evidence_and_data_science/#comment-4257220966"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![trevor_hastie_reply](figures/TrevorHastie_Reply_small.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, de acordo com a resposta do **Trevor Hastie** os valores de $\\alpha=0.10$ e $\\beta=0.38$ correspondem a um *cutoff* $c=0.75$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated: c=0.75, alpha=0.10, beta=0.37\n",
      "Calculated: c=0.75, alpha=0.10, beta=0.38\n"
     ]
    }
   ],
   "source": [
    "alpha_simulated_c075 = alpha_simulation(0.75, f0_density, f1_density, sample_size, replicates)\n",
    "beta_simulated_c075 = beta_simulation(0.75, f0_density, f1_density, sample_size, replicates)\n",
    "\n",
    "alpha_calculated_c075 = alpha_calculation(0.75, 0.0, 0.5, 1.0, sample_size)\n",
    "beta_calculated_c075 = beta_calculation(0.75, 0.0, 0.5, 1.0, sample_size)\n",
    "\n",
    "print(\"Simulated: c=0.75, alpha={0:.2f}, beta={1:.2f}\".format(alpha_simulated_c075, beta_simulated_c075))\n",
    "print(\"Calculated: c=0.75, alpha={0:.2f}, beta={1:.2f}\".format(alpha_calculated_c075, beta_calculated_c075))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as funções `alpha_simulation(.)`, `beta_simulation(.)`, `alpha_calculation(.)` e `beta_calculation(.)` aqui implementadas reproduziram exatamente estes mesmos valores, então, a implementação das mesmas de fato está correta.\n",
    "\n",
    "Além disso, quando o **Trevor Hastie** diz que ***\"..., resulting in a threshold for x of .4\"*** ele está se referindo ao $k$ da fórmula abaixo que obtivemos anteriormente ao reproduzir os dados da Figura 2.2 analiticamente.\n",
    "\n",
    "$$\n",
    "\\bar{x} \\ge k \\text{, onde } k = \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$\n",
    "\n",
    "onde, o teste passa a ser:\n",
    "\n",
    "$$\n",
    "t_c(x) = \\left\\{ \\begin{array}{ll} 1\\enspace\\text{if } \\bar{x} \\ge k\\\\ 0\\enspace\\text{if } \\bar{x} \\lt k.\\end{array} \\right. \\enspace \\enspace \\text{, onde } k = \\frac{c\\sigma^2}{n\\left(\\mu_1-\\mu_0\\right)} + \\frac{\\left(\\mu_1+\\mu_0\\right)}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold for x (when cutoff c=0.75) = 0.4\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "m_0 = 0.0\n",
    "m_1 = 0.5\n",
    "variance = 1.0\n",
    "c = 0.75\n",
    "\n",
    "k = (c*variance)/(n*(m_1-m_0)) + (m_1+m_0)/2.0\n",
    "threshold_for_x = k\n",
    "\n",
    "print(\"threshold for x (when cutoff c=0.75) = {0:.1f}\".format(threshold_for_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Referências além do próprio livro:*\n",
    " - https://digitalcommons.usu.edu/gradreports/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [Algorithms and Inference](01.01.Algorithms-and-Inference.ipynb) | [Conteúdo](Index.ipynb) | [Bayesian Inference] >\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fmafonseca/casi/blob/master/notebooks/01.02.Frequentist-Inference.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
